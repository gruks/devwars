---
phase: 03-game-engine
plan: "02"
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - backend/src/services/execution.service.js
  backend/src/modules/evaluation/evaluation.controller.js
  backend/src/modules/evaluation/evaluation.routes.js
  backend/src/routes.js
autonomous: true

must_haves:
  truths:
    - "Code can be executed in sandbox environment"
    - "Test cases are evaluated against submitted code"
    - "Results include pass/fail for each test case"
    - "Evaluation API returns detailed results"
  artifacts:
    - path: "backend/src/services/execution.service.js"
      provides: "Wrapper for sandbox-service API"
      exports: ["executeCode"]
    - path: "backend/src/modules/evaluation/evaluation.controller.js"
      provides: "Testcase evaluation logic"
      exports: ["evaluateSolution", "evaluateTestcases"]
  key_links:
    - from: "evaluation.controller.js"
      to: "execution.service.js"
      via: "executeCode() call"
      pattern: "executeCode\\(language, code"
    - from: "execution.service.js"
      to: "sandbox-service"
      via: "POST http://localhost:3000/api/execute"
      pattern: "localhost:3000/api/execute"
---

<objective>
Create execution service wrapper and testcase evaluation engine.

Purpose: Enable code execution in sandbox environment and evaluate submitted code against test cases.
Output: Execution service and evaluation controller with testcase evaluation
</objective>

<execution_context>
@C:/Users/HP/.config/opencode/get-shit-done/workflows/execute-plan.md
@C:/Users/HP/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/03-game-engine/03-CONTEXT.md
@.planning/phases/03-game-engine/03-01-SUMMARY.md
@compilers/sandbox-service/src/api/routes.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Execution Service</name>
  <files>backend/src/services/execution.service.js</files>
  <action>
Create execution.service.js in backend/src/services/:
- Function executeCode({ language, code, input, timeout }):
  - Make POST request to http://localhost:3000/api/execute
  - Request body: { language, code, input, timeout }
  - Default timeout: 3000ms
  - Handle connection errors, return { success: false, error: message } on failure
  - Map sandbox language names: python->python, node->javascript, java->java, go->go, cpp->cpp
- Function executeWithInput({ language, code, input }):
  - Wrapper that calls executeCode with provided input
- Use axios for HTTP requests
- Export { executeCode, executeWithInput }
  </action>
  <verify>Service exports executeCode and executeWithInput functions; makes HTTP call to sandbox-service</verify>
  <done>Execution service wraps sandbox-service API with proper error handling</done>
</task>

<task type="auto">
  <name>Task 2: Create Evaluation Controller</name>
  <files>backend/src/modules/evaluation/evaluation.controller.js</files>
  <action>
Create evaluation.controller.js in backend/src/modules/evaluation/:
- Function evaluateTestcases({ language, code, testcases }):
  - Iterate through each testcase in the array
  - For each: call executeCode with testcase.input
  - Compare output (trim whitespace, exact match)
  - Return array of { passed: boolean, input, expected, actual, error? }
  - Track passed count and total count
- Function evaluateSolution({ questionId, code }):
  - Find question by ID (must exist)
  - Call evaluateTestcases with question.testcases
  - Calculate score: (passed / total) * 100
  - Return { questionId, score, totalTests, passedTests, results[] }
- Use AppError for errors, HTTP_STATUS for status codes
- Export { evaluateTestcases, evaluateSolution }
  </action>
  <verify>Controller exports evaluateTestcases and evaluateSolution; evaluates code against testcases</verify>
  <done>Evaluation controller compares output against expected, returns detailed results</done>
</task>

<task type="auto">
  <name>Task 3: Create Evaluation Routes</name>
  <files>backend/src/modules/evaluation/evaluation.routes.js, backend/src/routes.js</files>
  <action>
Create evaluation.routes.js:
- POST /evaluate - evaluateSolution (protected)
  - Body: { questionId, code }
  - Returns { questionId, score, totalTests, passedTests, results[] }

Then update backend/src/routes.js to add:
- router.use('/evaluation', require('./modules/evaluation/evaluation.routes.js'));
  </action>
  <verify>Routes registered; POST /api/v1/evaluation/evaluate works</verify>
  <done>Evaluation endpoint available at /api/v1/evaluation/evaluate</done>
</task>

</tasks>

<verification>
- Execution service properly calls sandbox-service API
- Testcases are evaluated correctly with pass/fail results
- Evaluation endpoint returns score and detailed results
</verification>

<success_criteria>
Code can be executed and evaluated against test cases with detailed results returned
</success_criteria>

<output>
After completion, create `.planning/phases/03-game-engine/03-02-SUMMARY.md`
</output>
